{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xgjwg5p2EGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LeakyReLU, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, ZeroPadding2D\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxYYvY_62Ggf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = keras.datasets.mnist.load_data()\n",
        "\n",
        "train_x = train_x.reshape(60000, 28, 28, 1)\n",
        "test_x = test_x.reshape(10000, 28, 28, 1)\n",
        "train_x = train_x.astype('float32')/255\n",
        "test_x = test_x.astype('float32')/255\n",
        "\n",
        "z_dim = 100\n",
        "width = 28\n",
        "height = 28\n",
        "channels = 1\n",
        "img_shape = (width, height, channels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWY7CwZXDnku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator\n",
        "adam = Adam(lr=0.0002, beta_1=0.5)\n",
        "\n",
        "generator = keras.Sequential(\n",
        "[\n",
        "    Dense(128 * 7 * 7, activation = 'relu', input_dim = z_dim),\n",
        "    Reshape((7, 7, 128)),\n",
        "    UpSampling2D(),\n",
        "    Conv2D(128, kernel_size = 3, padding = 'same', activation = 'relu'),\n",
        "    BatchNormalization(momentum = 0.8),\n",
        "    UpSampling2D(),\n",
        "    Conv2D(64, kernel_size = 3, padding = 'same', activation = 'relu'),\n",
        "    BatchNormalization(momentum=0.8),\n",
        "    Conv2D(1, kernel_size = 3, padding = 'same', activation = 'tanh')\n",
        "])\n",
        "\n",
        "# Discriminator\n",
        "discriminator = keras.Sequential(\n",
        "[\n",
        "    Conv2D(32, kernel_size = 3, strides = 2, input_shape = img_shape, padding = 'same'),\n",
        "    LeakyReLU(alpha = 0.2),\n",
        "    Conv2D(64, kernel_size = 3, strides = 2, padding = 'same'),\n",
        "    BatchNormalization(momentum = 0.8),\n",
        "    LeakyReLU(alpha = 0.2),\n",
        "    Conv2D(128, kernel_size = 3, strides = 2, padding = 'same'),\n",
        "    BatchNormalization(momentum = 0.8),\n",
        "    LeakyReLU(alpha = 0.2),\n",
        "    Conv2D(256, kernel_size = 3, strides = 1, padding = 'same'),\n",
        "    BatchNormalization(momentum = 0.8),\n",
        "    LeakyReLU(alpha = 0.2),\n",
        "    Flatten(),\n",
        "    Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "generator.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "discriminator.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "\n",
        "discriminator.trainable = False\n",
        "\n",
        "inputs = Input(shape = (z_dim,))\n",
        "hidden = generator(inputs)\n",
        "output = discriminator(hidden)\n",
        "gan = keras.Model(inputs, output)\n",
        "gan.compile(loss = 'binary_crossentropy', optimizer = adam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tp0-sLZCX7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(losses):\n",
        "    '''\n",
        "    @losses.keys():\n",
        "        0: loss\n",
        "        1: accuracy\n",
        "    '''\n",
        "    d_loss = [v[0] for v in losses['D']]\n",
        "    g_loss = [v[0] for v in losses['G']]\n",
        "    \n",
        "    plt.figure(figsize = (10,8))\n",
        "    plt.plot(d_loss, label = 'Discriminator loss')\n",
        "    plt.plot(g_loss, label = 'Generator loss')\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "def plot_generated(n_ex = 2, dim = (1, 2), figsize = (12, 2)):\n",
        "    noise = np.random.normal(0, 1, size = (n_ex, z_dim))\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = generated_images.reshape(generated_images.shape[0], width, height)\n",
        "    plt.figure(figsize = figsize)\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generated_images[i, :, :], interpolation = 'nearest', cmap = 'gray_r')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTNkt28Xzhze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = {\"D\":[], \"G\":[]}\n",
        "samples = []\n",
        "\n",
        "def train(epochs = 100, plt_frq = 10, batch_size = 32):\n",
        "    batchCount = int(train_x.shape[0] / batch_size)\n",
        "    print('Epochs:', epochs)\n",
        "    print('Batch size:', batch_size)\n",
        "    print('Batches per epoch:', batchCount)\n",
        "    \n",
        "    y1 = np.zeros(2 * batch_size)\n",
        "    y1[:batch_size] = 1\n",
        "    y2 = np.ones(batch_size)\n",
        "    \n",
        "    for e in range(1, epochs+1):\n",
        "        if e == 1 or e%plt_frq == 0:\n",
        "            print('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        for _ in range(batchCount):\n",
        "            \n",
        "            image_batch = train_x[np.random.randint(0, train_x.shape[0], size = batch_size)]\n",
        "#             image_batch = image_batch.reshape(image_batch.shape[0], image_batch.shape[1], image_batch.shape[2], 1)\n",
        "            \n",
        "            # Create noise vectors for the generator\n",
        "            noise = np.random.normal(0, 1, size = (batch_size, z_dim))\n",
        "            \n",
        "            # Generate the images from the noise\n",
        "            generated_images = generator.predict(noise)\n",
        "            samples.append(generated_images)\n",
        "            imgs = np.concatenate((image_batch, generated_images))            \n",
        "\n",
        "            # Train discriminator on generated images\n",
        "            discriminator.trainable = True\n",
        "            d_loss = discriminator.train_on_batch(imgs, y1)\n",
        "\n",
        "            # Train generator\n",
        "            noise = np.random.normal(0, 1, size = (batch_size, z_dim))\n",
        "            \n",
        "            discriminator.trainable = False\n",
        "            g_loss = gan.train_on_batch(noise, y2)\n",
        "\n",
        "        # Only store losses from final batch of epoch\n",
        "        losses[\"D\"].append(d_loss)\n",
        "        losses[\"G\"].append(g_loss)\n",
        "\n",
        "        # Update the plots\n",
        "        if e == 1 or e%plt_frq == 0:\n",
        "            plot_generated()\n",
        "    plot_loss(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BDVcI2q3YDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}