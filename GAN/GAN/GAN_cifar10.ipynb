{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_cifar10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZRv8yiF9KwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LeakyReLU, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, ZeroPadding2D\n",
        "\n",
        "\n",
        "class GAN(object):\n",
        "    def __init__(self):\n",
        "        self.z_dim = 100\n",
        "        self.width = 32\n",
        "        self.height = 32\n",
        "        self.channels = 3\n",
        "        self.img_shape = (self.width, self.height, self.channels)\n",
        "        self.adam = Adam(lr=0.002, beta_1=0.5)\n",
        "        \n",
        "        self.generator = self.Build_Generator()\n",
        "        self.generator.compile(loss = 'binary_crossentropy', optimizer = self.adam, metrics = ['accuracy'])\n",
        "        \n",
        "        self.discriminator = self.Build_Discriminator()\n",
        "        self.discriminator.compile(loss = 'binary_crossentropy', optimizer = self.adam, metrics = ['accuracy'])\n",
        "        self.discriminator.trainable = False\n",
        "        \n",
        "        inputs = Input(shape = (self.z_dim,))\n",
        "        hidden = self.generator(inputs)\n",
        "        output = self.discriminator(hidden)\n",
        "        self.combined = keras.Model(inputs, output)\n",
        "        self.combined.compile(loss = 'binary_crossentropy', optimizer = self.adam)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def Build_Generator(self):\n",
        "        model = keras.Sequential(\n",
        "        [\n",
        "            Dense(128 * 8 * 8, activation = 'relu', input_dim = self.z_dim),\n",
        "            Reshape((8, 8, 128)),\n",
        "            UpSampling2D(),\n",
        "            Conv2D(128, kernel_size = 3, padding = 'same', activation = 'relu'),\n",
        "            BatchNormalization(),\n",
        "            UpSampling2D(),\n",
        "            Conv2D(64, kernel_size = 3, padding = 'same', activation = 'relu'),\n",
        "            BatchNormalization(),\n",
        "            Conv2D(3, kernel_size = 3, padding = 'same', activation = 'tanh')\n",
        "        ])\n",
        "        \n",
        "        return model\n",
        "    \n",
        "    \n",
        "    def Build_Discriminator(self):\n",
        "        model = keras.Sequential(\n",
        "        [\n",
        "            Conv2D(32, kernel_size = 3, strides = 2, input_shape = self.img_shape, padding = 'same'),\n",
        "            LeakyReLU(alpha = 0.2),\n",
        "            Conv2D(64, kernel_size = 3, strides = 2, padding = 'same'),\n",
        "            BatchNormalization(momentum = 0.8),\n",
        "            LeakyReLU(alpha = 0.2),\n",
        "            Conv2D(128, kernel_size = 3, strides = 2, padding = 'same'),\n",
        "            BatchNormalization(momentum = 0.8),\n",
        "            LeakyReLU(alpha = 0.2),\n",
        "            Conv2D(256, kernel_size = 3, strides = 1, padding = 'same'),\n",
        "            BatchNormalization(momentum = 0.8),\n",
        "            LeakyReLU(alpha = 0.2),\n",
        "            Flatten(),\n",
        "            Dense(1, activation = 'sigmoid')\n",
        "        ])\n",
        "        \n",
        "        return model\n",
        "    \n",
        "    \n",
        "    def Plot_Generated(self, n_ex = 5, dim = (1, 5), figsize = (12, 2)):\n",
        "        noise = np.random.normal(0, 1, size = (n_ex, self.z_dim))\n",
        "        generated_images = self.generator.predict(noise)\n",
        "        generated_images = generated_images.reshape(generated_images.shape[0], self.width, self.height)\n",
        "        plt.figure(figsize = figsize)\n",
        "        for i in range(generated_images.shape[0]):\n",
        "            plt.subplot(dim[0], dim[1], i+1)\n",
        "            plt.imshow(generated_images[i, :, :], interpolation = 'nearest', cmap = 'gray_r')\n",
        "            plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        \n",
        "    def Train(self, epochs = 15000, plt_frq = 5000, batch_size = 128):\n",
        "        (train_x, _), (_, _) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "        train_x = train_x.reshape(60000, self.width, self.height, self.channels)\n",
        "        train_x = train_x.astype('float32')/255\n",
        "        \n",
        "        print('Epochs:', epochs)\n",
        "        print('Batch size:', batch_size)\n",
        "\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            idx = np.random.randint(0, train_x.shape[0], batch_size)\n",
        "            imgs = train_x[idx]\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "            self.discriminator.trainable = True\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            self.discriminator.trainable = False\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "\n",
        "            if epoch%plt_frq == 0 or epoch == epochs - 1:\n",
        "                print('-----------', 'Epoch %d' % epoch, '-----------')\n",
        "                print('%d [D loss: %f, acc.: %.2f%%] [G loss: %f]' % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "                self.Plot_Generated()\n",
        "                \n",
        "    def Save_Model(self):\n",
        "        self.generator.save('generator_model.h5')\n",
        "        self.discriminator.save('discriminator_model.h5')\n",
        "        self.combined.save('combined_model.h5')\n",
        "\n",
        "                \n",
        "if __name__ == '__main__':\n",
        "    gan = GAN()\n",
        "    gan.Train()\n",
        "    gan.Save_Model()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}